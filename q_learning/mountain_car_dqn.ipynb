{"cells":[{"metadata":{},"cell_type":"markdown","source":"[![Binder](https://mybinder.org/badge_logo.svg)](https://lab.mlpack.org/v2/gh/mlpack/examples/master?urlpath=lab%2Ftree%2Fq_learning%2Facrobot_dqn.ipynb)\n\nYou can easily run this notebook at https://lab.mlpack.org/\n\nThis notebook is shows how to get use 3-Step Double DQN with Prioritized Replay to train an agent to get high scores for the [Acrobot](https://gym.openai.com/envs/Acrobot-v1) environment. \n\nWe make the agent train and test on OpenAI Gym toolkit's GUI interface provided through a distributed infrastructure (TCP API). More details can be found [here](https://github.com/zoq/gym_tcp_api).\n\nA video of the trained agent can be seen in the end."},{"metadata":{},"cell_type":"markdown","source":"## Including necessary libraries and namespaces"},{"metadata":{"trusted":true},"cell_type":"code","source":"#include <mlpack/core.hpp>","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#include <mlpack/methods/ann/ffn.hpp>\n#include <mlpack/methods/reinforcement_learning/q_learning.hpp>\n#include <mlpack/methods/reinforcement_learning/q_networks/simple_dqn.hpp>\n#include <mlpack/methods/reinforcement_learning/environment/env_type.hpp>\n#include <mlpack/methods/reinforcement_learning/policy/greedy_policy.hpp>\n#include <mlpack/methods/reinforcement_learning/training_config.hpp>","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"// Used to run the agent on gym's environment (provided externally) for testing.\n#include <gym/environment.hpp>","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"// Used to generate and display a video of the trained agent.\n#include \"xwidgets/ximage.hpp\"\n#include \"xwidgets/xvideo.hpp\"\n#include \"xwidgets/xaudio.hpp\"","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"using namespace mlpack;","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"using namespace mlpack::ann;","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"using namespace ens;","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"using namespace mlpack::rl;","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initializing the agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"// Set up the state and action space.\nDiscreteActionEnv::State::dimension = 2;\nDiscreteActionEnv::Action::size = 3;","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"// Set up the network.\nFFN<MeanSquaredError<>, GaussianInitialization> network(\n    MeanSquaredError<>(), GaussianInitialization(0, 0.001));\nnetwork.Add<Linear<>>(DiscreteActionEnv::State::dimension, 128);\nnetwork.Add<ReLULayer<>>();\nnetwork.Add<Linear<>>(128, DiscreteActionEnv::Action::size);\n// Set up the network.\nSimpleDQN<> model(network);","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"// Set up the policy method.\nGreedyPolicy<DiscreteActionEnv> policy(1.0, 1000, 0.1, 0.99);\nRandomReplay<DiscreteActionEnv> replayMethod(32, 10000);","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"// Set up training configurations.\nTrainingConfig config;\nconfig.TargetNetworkSyncInterval() = 100;\nconfig.ExplorationSteps() = 200*10;","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"// Set up DQN agent.\nQLearning<DiscreteActionEnv, decltype(model), AdamUpdate, decltype(policy), decltype(replayMethod)>\n    agent(config, model, policy, replayMethod);","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparation for training the agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"// Set up the gym training environment.\ngym::Environment env(\"gym.kurg.org\", \"4040\", \"MountainCar-v0\");\n\n// Initializing training variables.\nstd::vector<double> returnList;\nsize_t episodes = 0;\nbool converged = true;\n\n// The number of episode returns to keep track of.\nsize_t consecutiveEpisodes = 50;","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"// Function to train the agent on mlpack's own implementation of the CartPole environment.\nvoid train(const size_t numSteps)\n{\n  agent.Deterministic() = false;\n  std::cout << \"Training for \" << numSteps << \" steps.\" << std::endl;\n  while (agent.TotalSteps() < numSteps)\n  {\n    double episodeReturn = 0;\n    double adjustedEpisodeReturn = 0;\n    env.reset();\n    do\n    {\n      agent.State().Data() = env.observation;\n      agent.SelectAction();\n      arma::mat action = {double(agent.Action().action)};\n\n      env.step(action);\n      DiscreteActionEnv::State nextState;\n      nextState.Data() = env.observation;\n      \n      // Use an adjusted reward for task completion.\n      double adjustedReward = env.reward;\n      if (nextState.Data()[0] < -0.8)\n        adjustedReward += 0.5;\n\n      replayMethod.Store(agent.State(), agent.Action(), adjustedReward, nextState,\n          env.done, 0.99);\n      episodeReturn += env.reward;\n      adjustedEpisodeReturn += adjustedReward;\n      agent.TotalSteps()++;\n      if (agent.Deterministic() || agent.TotalSteps() < config.ExplorationSteps())\n        continue;\n      agent.TrainAgent();\n    } while (!env.done);\n    returnList.push_back(episodeReturn);\n    episodes += 1;\n\n    if (returnList.size() > consecutiveEpisodes)\n      returnList.erase(returnList.begin());\n        \n    double averageReturn = std::accumulate(returnList.begin(),\n                                           returnList.end(), 0.0) /\n                           returnList.size();\n    if(episodes % 1 == 0)\n    {\n      std::cout << \"Avg return in last \" << consecutiveEpisodes\n          << \" episodes: \" << averageReturn\n          << \"\\t Episode return: \" << episodeReturn\n          << \"\\t Adjusted return: \" << adjustedEpisodeReturn\n          << \"\\t Total steps: \" << agent.TotalSteps() << std::endl;\n    }\n  }\n}","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let the training begin"},{"metadata":{"trusted":true},"cell_type":"code","source":"// Training the agent for a total of at least 100 episodes.\ntrain(200*100)","execution_count":16,"outputs":[{"output_type":"stream","text":"Training for 20000 steps.\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 1000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 1200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 1400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 1600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 1800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 2000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 2200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 2400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 2600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 2800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 3000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 3200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193.5\t Total steps: 3400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 3600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 3800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 4000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 4200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 4400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193.5\t Total steps: 4600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193\t Total steps: 4800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 5000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 5200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 5400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 5600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193\t Total steps: 5800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193.5\t Total steps: 6000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -192\t Total steps: 6200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -197\t Total steps: 6400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 6600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 6800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 7000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -178.5\t Total steps: 7200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 7400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -195\t Total steps: 7600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 7800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -172.5\t Total steps: 8000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 8200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 8400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -177.5\t Total steps: 8600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -185.5\t Total steps: 8800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 9000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 9200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -198.5\t Total steps: 9400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -182\t Total steps: 9600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -181\t Total steps: 9800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 10000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -179.5\t Total steps: 10200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193.5\t Total steps: 10400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -188\t Total steps: 10600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -185\t Total steps: 10800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 11000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -174\t Total steps: 11200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 11400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -176\t Total steps: 11600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -195\t Total steps: 11800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -179.5\t Total steps: 12000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193\t Total steps: 12200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -188.5\t Total steps: 12400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 12600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -194.5\t Total steps: 12800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -183.5\t Total steps: 13000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 13200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -196.5\t Total steps: 13400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -182.5\t Total steps: 13600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -185.5\t Total steps: 13800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 14000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -189.5\t Total steps: 14200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 14400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -199\t Total steps: 14600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 14800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -170.5\t Total steps: 15000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 15200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 15400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -186\t Total steps: 15600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -176.5\t Total steps: 15800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 16000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -189.5\t Total steps: 16200\n","name":"stdout"},{"output_type":"stream","text":"Avg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 16400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193.5\t Total steps: 16600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 16800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 17000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -188.5\t Total steps: 17200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -190.5\t Total steps: 17400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 17600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -189.5\t Total steps: 17800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -171\t Total steps: 18000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -185\t Total steps: 18200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -199\t Total steps: 18400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -194.5\t Total steps: 18600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 18800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -195.5\t Total steps: 19000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -182.5\t Total steps: 19200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -194.5\t Total steps: 19400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -189\t Total steps: 19600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -178\t Total steps: 19800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -195\t Total steps: 20000\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Testing the trained agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"agent.Deterministic() = true;\n\n// Creating and setting up the gym environment for testing.\ngym::Environment envTest(\"gym.kurg.org\", \"4040\", \"MountainCar-v0\");\nenvTest.monitor.start(\"./dummy/\", true, true);\n\n// Resets the environment.\nenvTest.reset();\nenvTest.render();\n\ndouble totalReward = 0;\nsize_t totalSteps = 0;\n\n// Testing the agent on gym's environment.\nwhile (1)\n{\n  // State from the environment is passed to the agent's internal representation.\n  agent.State().Data() = envTest.observation;\n\n  // With the given state, the agent selects an action according to its defined policy.\n  agent.SelectAction();\n\n  // Action to take, decided by the policy.\n  arma::mat action = {double(agent.Action().action)};\n\n  envTest.step(action);\n  totalReward += envTest.reward;\n  totalSteps += 1;\n\n  if (envTest.done)\n  {\n    std::cout << \" Total steps: \" << totalSteps << \"\\t Total reward: \"\n        << totalReward << std::endl;\n    break;\n  }\n\n  // Uncomment the following lines to see the reward and action in each step.\n  // std::cout << \" Current step: \" << totalSteps << \"\\t current reward: \"\n  //   << totalReward << \"\\t Action taken: \" << action;\n}\n\nenvTest.close();\nstd::string url = envTest.url();\n\nauto video = xw::video_from_url(url).finalize();\nvideo","execution_count":17,"outputs":[{"output_type":"stream","text":" Total steps: 200\t Total reward: -200\n","name":"stdout"},{"output_type":"execute_result","execution_count":17,"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"daefcfc1f99b474eae344be4163e0320","version_major":2,"version_minor":0},"text/plain":"A Jupyter widget"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## A little more training..."},{"metadata":{"trusted":true},"cell_type":"code","source":"// Training the same agent for a total of at least 300 episodes.\ntrain(200*300)","execution_count":18,"outputs":[{"output_type":"stream","text":"Training for 60000 steps.\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -192.5\t Total steps: 20200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 20400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -190\t Total steps: 20600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -186\t Total steps: 20800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 21000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 21200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -180.5\t Total steps: 21400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -192.5\t Total steps: 21600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -175\t Total steps: 21800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -182\t Total steps: 22000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191\t Total steps: 22200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 22400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -178.5\t Total steps: 22600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191.5\t Total steps: 22800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -190.5\t Total steps: 23000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -196\t Total steps: 23200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193\t Total steps: 23400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 23600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -177\t Total steps: 23800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -187.5\t Total steps: 24000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -195.5\t Total steps: 24200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -175.5\t Total steps: 24400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 24600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 24800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -176.5\t Total steps: 25000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 25200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 25400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -179.5\t Total steps: 25600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -188\t Total steps: 25800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 26000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -175.5\t Total steps: 26200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -180\t Total steps: 26400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191.5\t Total steps: 26600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -179.5\t Total steps: 26800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 27000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191\t Total steps: 27200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -195.5\t Total steps: 27400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -170.5\t Total steps: 27600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -178\t Total steps: 27800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 28000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -196.5\t Total steps: 28200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 28400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -198.5\t Total steps: 28600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -189.5\t Total steps: 28800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -189\t Total steps: 29000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -192.5\t Total steps: 29200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -192\t Total steps: 29400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 29600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -175\t Total steps: 29800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -170.5\t Total steps: 30000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 30200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 30400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 30600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 30800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -173.5\t Total steps: 31000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -196\t Total steps: 31200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 31400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193\t Total steps: 31600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -177\t Total steps: 31800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -199\t Total steps: 32000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 32200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -187\t Total steps: 32400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -199\t Total steps: 32600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -187.5\t Total steps: 32800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -187\t Total steps: 33000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 33200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 33400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -196.5\t Total steps: 33600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 33800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -172\t Total steps: 34000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -194.5\t Total steps: 34200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 34400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -185.5\t Total steps: 34600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 34800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -188\t Total steps: 35000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 35200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 35400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -178.5\t Total steps: 35600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -181\t Total steps: 35800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -184\t Total steps: 36000\n","name":"stdout"},{"output_type":"stream","text":"Avg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -192\t Total steps: 36200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 36400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 36600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 36800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191\t Total steps: 37000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -187.5\t Total steps: 37200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191.5\t Total steps: 37400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 37600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -186.5\t Total steps: 37800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -196.5\t Total steps: 38000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -192.5\t Total steps: 38200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -190.5\t Total steps: 38400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 38600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -194.5\t Total steps: 38800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -189.5\t Total steps: 39000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -182.5\t Total steps: 39200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 39400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -178\t Total steps: 39600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 39800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 40000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 40200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -190.5\t Total steps: 40400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191\t Total steps: 40600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 40800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -176\t Total steps: 41000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -183\t Total steps: 41200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 41400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -195\t Total steps: 41600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -182\t Total steps: 41800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -188.5\t Total steps: 42000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -192\t Total steps: 42200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -186.5\t Total steps: 42400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 42600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191.5\t Total steps: 42800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -194\t Total steps: 43000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 43200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 43400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -190.5\t Total steps: 43600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 43800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -184\t Total steps: 44000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 44200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 44400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 44600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -188.5\t Total steps: 44800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -174\t Total steps: 45000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 45200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 45400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 45600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -189.5\t Total steps: 45800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -186\t Total steps: 46000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191.5\t Total steps: 46200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -194.5\t Total steps: 46400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -185.5\t Total steps: 46600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -176.5\t Total steps: 46800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -196\t Total steps: 47000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -192.5\t Total steps: 47200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191\t Total steps: 47400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 47600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -192\t Total steps: 47800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -169.5\t Total steps: 48000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -173\t Total steps: 48200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -198\t Total steps: 48400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 48600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -189.5\t Total steps: 48800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -191.5\t Total steps: 49000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 49200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 49400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -175.5\t Total steps: 49600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -175\t Total steps: 49800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 50000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 50200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 50400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -180.5\t Total steps: 50600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -194.5\t Total steps: 50800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -180\t Total steps: 51000\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -187.5\t Total steps: 51200\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -193\t Total steps: 51400\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -200\t Total steps: 51600\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -190\t Total steps: 51800\nAvg return in last 50 episodes: -200\t Episode return: -200\t Adjusted return: -194.5\t Total steps: 52000\n","name":"stdout"},{"output_type":"stream","text":"Avg return in last 50 episodes: -199.98\t Episode return: -199\t Adjusted return: -187.5\t Total steps: 52199\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 52399\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 52599\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -189.5\t Total steps: 52799\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 52999\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -172\t Total steps: 53199\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 53399\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -188\t Total steps: 53599\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -190.5\t Total steps: 53799\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -188\t Total steps: 53999\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 54199\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -188.5\t Total steps: 54399\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -180.5\t Total steps: 54599\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 54799\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -193\t Total steps: 54999\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -187\t Total steps: 55199\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -198\t Total steps: 55399\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -188.5\t Total steps: 55599\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 55799\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -197.5\t Total steps: 55999\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 56199\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -192.5\t Total steps: 56399\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -181.5\t Total steps: 56599\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 56799\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 56999\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -187\t Total steps: 57199\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 57399\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 57599\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -195\t Total steps: 57799\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 57999\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -189.5\t Total steps: 58199\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -189\t Total steps: 58399\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -193.5\t Total steps: 58599\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 58799\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -187.5\t Total steps: 58999\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -187.5\t Total steps: 59199\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 59399\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -198\t Total steps: 59599\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -190\t Total steps: 59799\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 59999\nAvg return in last 50 episodes: -199.98\t Episode return: -200\t Adjusted return: -200\t Total steps: 60199\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Final agent testing!"},{"metadata":{"trusted":true},"cell_type":"code","source":"agent.Deterministic() = true;\n\n// Creating and setting up the gym environment for testing.\ngym::Environment envTest(\"gym.kurg.org\", \"4040\", \"MountainCar-v0\");\nenvTest.monitor.start(\"./dummy/\", true, true);\n\n// Resets the environment.\nenvTest.reset();\nenvTest.render();\n\ndouble totalReward = 0;\nsize_t totalSteps = 0;\n\n// Testing the agent on gym's environment.\nwhile (1)\n{\n  // State from the environment is passed to the agent's internal representation.\n  agent.State().Data() = envTest.observation;\n\n  // With the given state, the agent selects an action according to its defined policy.\n  agent.SelectAction();\n\n  // Action to take, decided by the policy.\n  arma::mat action = {double(agent.Action().action)};\n\n  envTest.step(action);\n  totalReward += envTest.reward;\n  totalSteps += 1;\n\n  if (envTest.done)\n  {\n    std::cout << \" Total steps: \" << totalSteps << \"\\t Total reward: \"\n        << totalReward << std::endl;\n    break;\n  }\n\n  // Uncomment the following lines to see the reward and action in each step.\n  // std::cout << \" Current step: \" << totalSteps << \"\\t current reward: \"\n  //   << totalReward << \"\\t Action taken: \" << action;\n}\n\nenvTest.close();\nstd::string url = envTest.url();\n\nauto video = xw::video_from_url(url).finalize();\nvideo","execution_count":19,"outputs":[{"output_type":"stream","text":" Total steps: 200\t Total reward: -200\n","name":"stdout"},{"output_type":"execute_result","execution_count":19,"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc9080f698634a3c8ad472df07f5c094","version_major":2,"version_minor":0},"text/plain":"A Jupyter widget"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"xcpp14","display_name":"C++14","language":"C++14"},"language_info":{"codemirror_mode":"text/x-c++src","file_extension":".cpp","mimetype":"text/x-c++src","name":"c++","version":"14"}},"nbformat":4,"nbformat_minor":2}